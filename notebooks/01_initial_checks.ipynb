{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Craigslist Vehicles \u2014 Initial Data Checks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook performs preliminary profiling on the `vehicles.csv` dataset to understand schema, data quality, duplicates, and outlier behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import csv\n",
        "\n",
        "DATA_PATH = Path('data/vehicles.csv')\n",
        "with DATA_PATH.open() as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    records = list(reader)\n",
        "\n",
        "len(records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': '1', 'url': 'https://example.com/1', 'region': 'seattle', 'region_url': 'https://seattle.craigslist.org', 'price': '8500', 'year': '2012', 'manufacturer': 'honda', 'model': 'civic lx', 'condition': 'good', 'cylinders': '4 cylinders', 'fuel': 'gas', 'odometer': '120000', 'title_status': 'clean', 'transmission': 'automatic', 'VIN': '1HGCM82633A123456', 'drive': 'fwd', 'size': 'compact', 'type': 'sedan', 'paint_color': 'blue', 'image_url': 'https://images.craigslist.org/1', 'description': 'Reliable daily driver with maintenance records.', 'county': 'king county', 'state': 'wa', 'lat': '47.6062', 'long': '-122.3321', 'posting_date': '2021-05-15T10:30:00-0700'}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "records[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "column       | dtype  | unique | missing | missing_pct\n-------------+--------+--------+---------+------------\nid           | int    | 6      | 0       | 0.0%       \nurl          | object | 6      | 0       | 0.0%       \nregion       | object | 4      | 0       | 0.0%       \nregion_url   | object | 4      | 0       | 0.0%       \nprice        | int    | 5      | 0       | 0.0%       \nyear         | int    | 5      | 0       | 0.0%       \nmanufacturer | object | 5      | 0       | 0.0%       \nmodel        | object | 5      | 0       | 0.0%       \ncondition    | object | 4      | 0       | 0.0%       \ncylinders    | object | 4      | 0       | 0.0%       \nfuel         | object | 2      | 0       | 0.0%       \nodometer     | int    | 5      | 0       | 0.0%       \ntitle_status | object | 2      | 0       | 0.0%       \ntransmission | object | 2      | 0       | 0.0%       \nVIN          | object | 5      | 0       | 0.0%       \ndrive        | object | 2      | 0       | 0.0%       \nsize         | object | 4      | 0       | 0.0%       \ntype         | object | 3      | 0       | 0.0%       \npaint_color  | object | 5      | 0       | 0.0%       \nimage_url    | object | 5      | 0       | 0.0%       \ndescription  | object | 6      | 0       | 0.0%       \ncounty       | object | 4      | 0       | 0.0%       \nstate        | object | 4      | 0       | 0.0%       \nlat          | float  | 5      | 0       | 0.0%       \nlong         | float  | 5      | 0       | 0.0%       \nposting_date | object | 5      | 0       | 0.0%       \n"
          ]
        }
      ],
      "source": [
        "# Summaries: inferred dtypes, unique counts, and missingness\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def infer_type(values):\n",
        "    types = set()\n",
        "    for v in values:\n",
        "        if v == '' or v is None:\n",
        "            continue\n",
        "        try:\n",
        "            int(v)\n",
        "        except ValueError:\n",
        "            try:\n",
        "                float(v)\n",
        "            except ValueError:\n",
        "                types.add('object')\n",
        "            else:\n",
        "                types.add('float')\n",
        "        else:\n",
        "            types.add('int')\n",
        "    if 'object' in types:\n",
        "        return 'object'\n",
        "    if 'float' in types and 'int' in types:\n",
        "        return 'float'\n",
        "    if 'float' in types:\n",
        "        return 'float'\n",
        "    if 'int' in types:\n",
        "        return 'int'\n",
        "    return 'object'\n",
        "\n",
        "columns = list(records[0].keys())\n",
        "values_by_col = {col: [row[col] for row in records] for col in columns}\n",
        "unique_counts = {col: len({v for v in vals}) for col, vals in values_by_col.items()}\n",
        "missing_counts = {col: sum(1 for v in vals if v == '' or v is None) for col, vals in values_by_col.items()}\n",
        "missing_pct = {col: (missing_counts[col] / len(records)) * 100 for col in columns}\n",
        "dtypes = {col: infer_type(vals) for col, vals in values_by_col.items()}\n",
        "\n",
        "\n",
        "def format_table(rows, headers):\n",
        "    widths = [len(h) for h in headers]\n",
        "    for row in rows:\n",
        "        for i, cell in enumerate(row):\n",
        "            widths[i] = max(widths[i], len(str(cell)))\n",
        "    lines = []\n",
        "    header_line = ' | '.join(str(h).ljust(widths[i]) for i, h in enumerate(headers))\n",
        "    separator = '-+-'.join('-' * widths[i] for i in range(len(headers)))\n",
        "    lines.append(header_line)\n",
        "    lines.append(separator)\n",
        "    for row in rows:\n",
        "        lines.append(' | '.join(str(cell).ljust(widths[i]) for i, cell in enumerate(row)))\n",
        "    print('\\n'.join(lines))\n",
        "\n",
        "rows = [\n",
        "    (col, dtypes[col], unique_counts[col], missing_counts[col], f\"{missing_pct[col]:.1f}%\")\n",
        "    for col in columns\n",
        "]\n",
        "format_table(rows, ['column', 'dtype', 'unique', 'missing', 'missing_pct'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id: no duplicates detected\nurl: no duplicates detected\nVIN: 1 duplicate group(s) -> [('1HGCM82633A123456', [0, 5])]\n"
          ]
        }
      ],
      "source": [
        "# Duplicate checks across key identifiers\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def find_duplicates(key):\n",
        "    idx = defaultdict(list)\n",
        "    for i, row in enumerate(records):\n",
        "        value = row[key]\n",
        "        if value:\n",
        "            idx[value].append(i)\n",
        "    return {k: v for k, v in idx.items() if len(v) > 1}\n",
        "\n",
        "for key in ['id', 'url', 'VIN']:\n",
        "    dupes = find_duplicates(key)\n",
        "    if dupes:\n",
        "        print(f\"{key}: {len(dupes)} duplicate group(s) -> {sorted(dupes.items())}\")\n",
        "    else:\n",
        "        print(f\"{key}: no duplicates detected\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drop secondary entries sharing the same VIN while preserving the earliest listing by posting_date or lowest row index.\n"
          ]
        }
      ],
      "source": [
        "# Suggested deduplication strategy based on VIN duplicates\n",
        "print('Drop secondary entries sharing the same VIN while preserving the earliest listing by posting_date or lowest row index.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "price: min=2300.00, max=999999.00, mean=179466.50, p05=3850.00, p25=8500.00, p50=10500.00, p75=36875.00, p95=761249.25\nyear: min=1985.00, max=2020.00, mean=2007.17, p05=1988.50, p25=2002.25, p50=2012.00, p75=2014.25, p95=2018.75\nodometer: min=15000.00, max=220000.00, mean=100833.33, p05=23750.00, p25=57500.00, p50=100000.00, p75=120000.00, p95=195000.00\nlat: min=34.05, max=47.62, mean=43.69, p05=35.47, p25=41.18, p50=46.56, p75=47.61, p95=47.62\nlong: min=-122.68, max=-104.99, mean=-118.82, p05=-122.60, p25=-122.34, p50=-122.33, p75=-119.27, p95=-108.30\n"
          ]
        }
      ],
      "source": [
        "# Outlier diagnostics for key numeric columns\n",
        "from statistics import mean\n",
        "\n",
        "\n",
        "def parse_float_list(values):\n",
        "    parsed = []\n",
        "    for v in values:\n",
        "        if v == '' or v is None:\n",
        "            continue\n",
        "        parsed.append(float(v))\n",
        "    return parsed\n",
        "\n",
        "\n",
        "def quantiles(values, probs):\n",
        "    values = sorted(values)\n",
        "    n = len(values)\n",
        "    results = []\n",
        "    for p in probs:\n",
        "        pos = (n - 1) * (p / 100)\n",
        "        lower = int(pos)\n",
        "        upper = min(lower + 1, n - 1)\n",
        "        weight = pos - lower\n",
        "        results.append(values[lower] * (1 - weight) + values[upper] * weight)\n",
        "    return results\n",
        "\n",
        "for col in ['price', 'year', 'odometer', 'lat', 'long']:\n",
        "    series = parse_float_list(values_by_col[col])\n",
        "    q5, q25, q50, q75, q95 = quantiles(series, [5, 25, 50, 75, 95])\n",
        "    print(\n",
        "        f\"{col}: min={min(series):.2f}, max={max(series):.2f}, mean={mean(series):.2f}, \"\n",
        "        f\"p05={q5:.2f}, p25={q25:.2f}, p50={q50:.2f}, p75={q75:.2f}, p95={q95:.2f}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The extreme price value ($999,999) and the duplicate VIN indicate potential data-quality issues requiring manual review or rule-based filtering prior to modeling."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
